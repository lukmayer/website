---
description: "Lukas Mayer's research in computational cognitive science, Human-AI collaboration. Related topics include causal reasoning, inversion problems, AI alignment, data-science, software development"

listing:
  id: publications
  template: publication.ejs
  contents:
    - publications.yml
  sort-ui: false
  filter-ui: false
  page-size: 100
  field-display-names:
    title: "Title"
    journal: "Journal"
    authors: "Authors"
    image: "Image"
    osf: "OSF"
    paper: "Paper"
    paragraph-header: "Header"
    descriptive-paragraph: "Description"

resources: assets/cogsci25_poster.pdf

format: 
  html:
    toc: false
    callout-appearance: default
    code-overflow: wrap
    code-line-numbers: true
    code-block-border-left: false
---

::: {.column-page-inset-left}


<style>

.listing-descriptive-paragraph {
  transition: max-height 0.5s ease;
  overflow: hidden; /* Helps in controlling the transition */
}

.button-link {
  transition: transform 0.3s ease;
}

.button-link:hover {
  transform: scale(1.1);
}


/* Remove bullet points from the list */
.pub-list {
  list-style: none;
  padding: 0;
  margin: 0;
}

/* Set the pub-item as a flex container with vertical centering */
.pub-item {
  display: flex;
  gap: 20px;            
}

.responsive-pub-image {
  max-width: 100%;
  height: auto;
  border-radius: 0px;
  border: 1px solid #333;
  width: auto;
}

/* Responsive breakpoints */
@media (max-width: 768px) {
  .responsive-pub-image {
    max-width: 90%;
  }
}

@media (max-width: 480px) {
  .responsive-pub-image {
    max-width: 95%;
  }
}


/* Let the details container fill the remaining space */
.pub-details {
  flex: 1;
}
.highlight-author {
  font-weight: bold;
}

.special-header {
  font-weight: bold;
}

.listing-journal {
  font-weight: italic;
}


.description {
    display: none;
}

@media (max-width: 768px) {
  .pub-item {
    flex-direction: column;  
    gap: 15px;               
  }

  /* Adjust the image container  */
  .pub-image img {
    max-width: 80%; 
  }


}

.small-break {
  line-height: 0.1;
  font-size: 0.5em;
}


</style>


# Publications



## Published


::: {#publications}
:::


::: text-center

\

---


::: {.columns}

::: {.column width=50%}
<br class="small-break">
{{< ai google-scholar size=huge >}} [More on Google Scholar](https://scholar.google.com/citations?user=KsH37lMAAAAJ)
:::

::: {.column width=50%}
<br class="small-break">
{{< ai semantic-scholar size=huge >}} [More on Semantic Scholar](https://www.semanticscholar.org/author/Lukas-William-Mayer/2281033339)
:::

::: 
<!-- end columns -->

---

\

:::
<!-- end text-center -->

## Posters and Talks


::::: {.callout-important collapse="true" icon="false"}
# ***"A Cognitive Framework for Strategic AI Communication"***
**Mayer, L. W.**, Steyvers, M. *CogSci 2025*

::: text-center
<iframe src="assets/cogsci25_poster.pdf#toolbar=0&navpanes=0&scrollbar=0&view=FitH&page=1" style="width: 90%; height: 1000px; border: none;"></iframe>
:::

:::::


\


## In Progress


::::: {.callout-important collapse="true" icon="false"}
# ***"Waste not want not: Computational methods to maximise attendance in group research"***
**Mayer, L. W.**, Bocheva, D., Hinds, J., Brown, O., Piwek, L., Ellis, D. (under Review) *Behavior Research Methods*.

::: text-center
![](assets/sets.png)
:::

\

**Do your studies rely on groups of people?** Recruiting participants for group sessions can be arduous, often costing a lot of time, effort, and resources.
In this work, we demonstrate the complete lack of tools that can appropriately allocate a sample of interested participants to a set of group sessions.
We then mathematically derive metrics that can quantify the effectiveness of any tool attempting to solve this problem.
Finally, we develop an algorithm that outperforms any existing utility on this task using simulation and a large-scale pre-registered user study.
Our scheduling utility is free and open-source, available to anyone through a web-applet.

::: text-center
[Link to the web-app](https://lukmayer.github.io/appointment_sets)
:::
:::::

::::: {.callout-important collapse="true" icon="false"}
# ***"Human-AI Collaboration: Trade-offs Between Performance and Preferences"*** 
**Mayer, L. W.**, Karny, S., Ayoub, J., Song, M., Tian, D., Moradi-Pari, E., Steyvers, M. (under Review) *Cognitive Research: Principles and Implications*

::: text-center
![](assets/collab_ai.png)
:::

\

**How can we make AI collaborate well with people?** Narrowly optimizing the performance of AI agents may be convenient, but can cause frustration when people are then asked to work with this agent.
In this paper, we show that people prefer AI agents that are considerate of their preferences, even when this comes at the cost of performance.
We also find that certain human-centric design choices boost people's liking of the agent, without harming the performance of the human-AI team.
Our results strongly suggest that leveraging both subjective and objective metrics is crucial when designing AI agents for human collaboration.

::: text-center
[OSF repository](https://osf.io/ybweq/?view_only=cb4d4c7ac0b848b79b6ae8c7b09278cc)
:::
:::::

\



<script>
document.addEventListener('DOMContentLoaded', function() {
  var myName = "Mayer, L. W.";
  var authorElements = document.querySelectorAll('.authors-string');
  var regex = new RegExp(myName, 'g');
  authorElements.forEach(function(elem) {
    elem.innerHTML = elem.innerHTML.replace(
      regex,
      '<span class="highlight-author">' + myName + '</span>'
    );
  });

</script>

<script>
document.addEventListener('DOMContentLoaded', function() {
  document.querySelectorAll('.callout-title-container').forEach(function(container) {
    container.addEventListener('click', function() {
      const index = this.getAttribute('data-index');
      const element = document.getElementById('pub-' + index);
      const arrow = this.querySelector('.toggle-arrow');

      if (element.style.display === 'none') {
        element.style.display = 'block';
        arrow.innerHTML = '▲';
      } else {
        element.style.display = 'none';
        arrow.innerHTML = '▼';
      }
    });
  });
});
</script>

\


# Research Interests


::: {.callout-important collapse="false" icon="false"}
## Inversion and Alignment problems in Cognitive Science & AI

Whenever people are interacting with machine-learning based systems, human biases can propagate through the model leading to distorted predictions. Therefore, one strand of work I am interested in pursuing in this area is to derive the transformations that lead to better alignment, thus increasing the validity of predictions. I am also interested in addressing more engineering related concerns, such as how to use information we possess about cognition to improve the performance of machine learning algorithms trained on human-generated information. In this type of work, I like to mix and match methods from Cognitive Science and Machine Learning in combination with large, real-world data-sets.

My recent work in this area can be broadly described with the umbrella term of "Human-AI collaboration". AI technologies are increasingly being integrated into various tools, but they oftentimes lack the ability to anticipate the needs of the human user. Using formal models of human cognition as part of these systems can help bridge this gap by describing mental processes people have in a language that AI systems can understand (math). This can lead to more efficient and effective collaboration between humans and AI systems, and can also help to identify potential pitfalls in the design of these systems.  
:::

\


::: {.callout-important collapse="false" icon="false"}
## Computational Cognitive Science

People possess a remarkable cognitive flexibility enabling us to solve problems in various domains that are still completely intractable to modern methods in Artificial Intelligence. Therefore, I think that by studying human behavior we may be able to reverse-engineer some of the machinery that gives rise to these amazing abilities, uncovering the structure that may pave the way for new kinds of algorithms.

At the moment, I am working on a project series aiming to develop a computational account of causal reasoning for intervention on other agents. In these projects I will be using a considerable amount of simulation, computational modelling, and a series of custom-designed web experiments to develop reasoning models that exhibit human-like abilities to flexibly generalize to new contexts. My goal here is to show how this causal account can outperform sophisticated Reinforcement Learning models in dynamic environments, which includes most of the real world.
:::


:::